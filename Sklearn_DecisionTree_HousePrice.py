# -*- coding: utf-8 -*-
"""houseprice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sjlDqiKKOeRePGJ93IHsd9D7DJpfxiSk
"""

from urllib.request import urlretrieve
import pandas as pd
train_df = pd.read_csv ("/content/drive/My Drive/Colab Notebooks/houseprice/train.csv")
test_df = pd.read_csv ("/content/drive/My Drive/Colab Notebooks/houseprice/test.csv")

datas = pd.concat([train_df, test_df], axis=0, ignore_index=True)
pd.set_option('max_rows', 100)
datas = datas.drop(["Id", "SalePrice"], axis=1)

datas

na = datas.isna ().sum()
pd.set_option('max_rows', 100)
na

na = datas.isna ().sum() # see if data is missing
# have something missing Series [True/False list/series]
na[na > 0].sort_values(ascending=False)

most = datas["LotFrontage"].value_counts().idxmax()
datas["LotFrontage"] = datas["LotFrontage"].fillna(most)
most = datas["GarageYrBlt"].value_counts().idxmax()
datas["GarageYrBlt"] = datas["GarageYrBlt"].fillna(most)
most = datas["MasVnrArea"].value_counts().idxmax()
datas["MasVnrArea"] = datas["MasVnrArea"].fillna(most)
most = datas["BsmtHalfBath"].value_counts().idxmax()
datas["BsmtHalfBath"] = datas["BsmtHalfBath"].fillna(most)
most = datas["BsmtFullBath"].value_counts().idxmax()
datas["BsmtFullBath"] = datas["BsmtFullBath"].fillna(most)
most = datas["GarageArea"].value_counts().idxmax()
datas["GarageArea"] = datas["GarageArea"].fillna(most)
most = datas["GarageCars"].value_counts().idxmax()
datas["GarageCars"] = datas["GarageCars"].fillna(most)
most = datas["TotalBsmtSF"].value_counts().idxmax()
datas["TotalBsmtSF"] = datas["TotalBsmtSF"].fillna(most)
most = datas["BsmtUnfSF"].value_counts().idxmax()
datas["BsmtUnfSF"] = datas["BsmtUnfSF"].fillna(most)
most = datas["BsmtFinSF2"].value_counts().idxmax()
datas["BsmtFinSF2"] = datas["BsmtFinSF2"].fillna(most)
most = datas["BsmtFinSF1"].value_counts().idxmax()
datas["BsmtFinSF1"] = datas["BsmtFinSF1"].fillna(most)

datas = pd.get_dummies(datas) # One-hot encoding for none-number items
datas = pd.get_dummies(datas, columns=["MSSubClass"])
datas = pd.get_dummies(datas, columns=["OverallQual"])
datas = pd.get_dummies(datas, columns=["OverallCond"])
datas

#different kind of ticket number with different numbers
dic = datas["YearBuilt"].value_counts()
print (dic)
def count (n):
  return dic[n]
#datas["YearBuilt"] = datas["YearBuilt"].apply(count)
#
#dic = datas["YearRemodAdd"].value_counts()
#datas["YearRemodAdd"] = datas["YearRemodAdd"].apply(count)

dic = datas["GarageYrBlt"].value_counts()
datas["GarageYrBlt"] = datas["GarageYrBlt"].apply(count)

x_train = datas.iloc[:len(train_df)]
x_predict = datas.iloc [len(train_df):]
y_train = train_df ["SalePrice"]

x_train

import numpy as np
from sklearn.model_selection import train_test_split

x, y = np.array(x_train), np.array(y_train)
x_train, x_test, y_train, y_test = train_test_split ( x, y, test_size = 0.2)
print (len(x_train), len(x_test))

from sklearn.tree import DecisionTreeRegressor 
reg = DecisionTreeRegressor (max_depth=5, random_state=1)
reg.fit (x_train,y_train)

from sklearn.metrics import r2_score
#sklearn.metrics.r2_score(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')

pre = reg.predict(x_test)
r2_score (y_test, pre)