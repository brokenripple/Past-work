# -*- coding: utf-8 -*-
"""Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DswE14nTP43O3THbnuiqJQfYcyRU960s

$ area = \frac {1} {2-i} \times \pi_3 2 $
"""

import sklearn
import matplotlib
from sklearn.datasets import load_iris 
import pandas as pd
iris = load_iris ()

# find the key of the dataset and rebuild the dataset as an array
for key, value in iris.items():
  print (key)

df = pd.DataFrame(iris["data"], columns = iris ["feature_names"])
pd.options.display.max_rows = 20
# df.to_csv ("iris.csv", encoding="utf-8", index = False)
df ["target"] = iris ["target"]
df

import numpy as np
from sklearn.model_selection import train_test_split


x, y = df.drop(["target"], axis=1), df["target"]
x, y = np.array(x), np.array(y)
x_train, x_test, y_train, y_test = train_test_split ( x, y, test_size = 0.1)
print (len(x_train), len(y_train))

from sklearn.tree import DecisionTreeClassifier as DTC
clf = DTC(max_depth=4)
clf.fit (x_train,y_train)

# Commented out IPython magic to ensure Python compatibility.
#熱度圖 heat map
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
df.corr()
plt.figure (figsize = (10,10)) 
sns.heatmap (df.astype("float").corr(), cmap = "OrRd", annot = True)



"""class sklearn.tree.DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)"""

from sklearn.tree import export_graphviz
import graphviz
g = export_graphviz (clf, feature_names = iris["feature_names"], class_names = iris["target_names"], filled= True)
graphviz.Source (g)

"""Gini index or Gini impurity measures the degree or probability of a particular variable being wrongly classified when it is randomly chosen. But what is actually meant by ‘impurity’? If all the elements belong to a single class, then it can be called pure. The degree of Gini index varies between 0 and 1, where 0 denotes that all elements belong to a certain class or if there exists only one class, and 1 denotes that the elements are randomly distributed across various classes. A Gini Index of 0.5 denotes equally distributed elements into some classes.


where pi  is the probability of an object being classified to a particular class.
"""

pre = clf.predict (x_test)
print (list(pre))
print (list(y_test))
from sklearn.metrics import accuracy_score
accuracy_score (clf.predict(x_test), y_test)
# search sklearn metrics

from sklearn.metrics import confusion_matrix
pd.DataFrame (confusion_matrix (y_test, pre))